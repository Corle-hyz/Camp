### 姓名
何咏哲

### 实习项目
全自动并行架构升级

### 本周工作

1. **探究异构集群的性质**

   * 异构的定义：广义上来说，异构集群指由具有不同硬件或软件配置的计算节点组成的计算集群。它可以指不同的计算资源如CPU、GPU、TPU、DCU等等，也可以指GPU中的不同平台如NV和AMD，或者同一平台下的不同型号，如V100、A100(40GB)、A100(80GB)。考虑到目前大部分用的还是NV的卡，所以这里的异构一般指最后一种。
  
   * 异构与同构在全自动并行上的区别：异构集群中的节点在处理器类型、内存大小、网络带宽等方面具有很大的差异，以全自动并行为例，以往的并行模式仅仅需要考虑单一设备下的峰值显存即可，但是异构环境需要对每一类设备进行逐一考虑，进一步的，并行模式对于模型、数据集等的拆分也不应该是均等的，否则无法达到负载均衡的效果，不能有效提高异构资源的利用率。
  
   * 对异构环境的建模：对于不同的计算卡，存在差异的主要有算力C、显存M和带宽B。显存和带宽都有比较明确的数值，在分布式训练领域，由于算力主要取决于Tensor Core的性能，因此算力可以用TFLOPS代表。

2. **初步构建一个异构体系下的全自动并行方案**

   * 原本的全自动并行方案：原本的全自动并行方案是对不同配置下分布式训练的（峰值）显存占用进行建模，从而将OOM的策略剪枝。并且仅仅使用少量资源在全量资源下对剩下的策略的性能进行profile，使得原本同时只能进行一次profile的规模，现在能同时进行多次profile。
  
   * 异构环境下的并行方案：异构环境对框架的灵活性有了更高的要求。例如，当使用PP时，如果还是简单的将模型拆成PP dimension个stage，很容易在异构环境下造成负载不均衡的状态。虽然部分框架目前还不支持（或不容易做到）这样高的自由度，但是对于建模来说应该充分考虑到这种情况。因此我们调整[原本的公式](https://github.com/Corle-hyz/Camp/blob/main/WeeklyReports/Hackathon_5th/12_Corle-hyz/%5BWeeklyReport%5D2023.11.08~2023.11.21.md)，原本是将一个模型沿着PP、DP等维度均等地拆分，现在将这个数量更改为可变的，具体数值由达到动态均衡的拆分算法来确定。通过这样的形式可以实现对异构环境下的显存占用进行建模。
  
   * 后续工作：借助显存公式完成动态均衡的拆分算法


### 下周工作

1. 完善异构体系下的全自动并行方案，将其参数化。

### 导师点评
本周初步次分析了异构体系下的全自动并行方案，期待进一步完善。
