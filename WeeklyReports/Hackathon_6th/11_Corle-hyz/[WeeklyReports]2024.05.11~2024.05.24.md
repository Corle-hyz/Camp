### 姓名
何咏哲

### 实习项目
全自动并行架构升级

### 本周工作

1. **借助显存公式完成动态均衡的拆分算法**

   * 负载均衡需要权衡的条件主要有三个：
     * 不会显存溢出（OOM）；
     * 不会因为计算能力的差异而带来等待（Bubble）；
     * 在此基础上尽可能地发挥硬件的独特优势。
  
   * 为达到上述三个目的，我们设计了一个异构体系下的全自动并行方案：
     * 首先将异构硬件的计算能力参数化（TFlops）；
     * 然后根据计算能力之间的比值，来决定PP和TP在异构设备间切分的比例；
     * 根据该比例，改变PP和TP等并行方式切分模型的位置及维度，运用已经完成的自动搜索算法（包括使用显存模型进行剪枝），快速得到异构体系下最优的训练配置。

2. **完善异构体系下的全自动并行方案，将其参数化**

   * 假设设备A的算力是CA、数量是NA，设备B的算力是CB、数量是NB。要在这样一个集群上训练一个n层的DNN网络。
   * 首先考虑A和B的全同子结构，该子结构中A的数量为SNA=NA/g.c.d(NA, NB), SNB=B的数量为NB/g.c.d(NA, NB)。
   * 确定两种设备的算力和之比(CA\*SNA)/(CB\*SNB)，该比例即两种设备计算的tokens数之比。
   * 考虑到异构设备一般是放置在不同节点内的，而节点间通信的带宽一般又远小于节点内的带宽，因此：
     * 首先将两种设备放到两个DP Rank中（Sharding），在各自内部运用自动搜索引擎进行剪枝；
     * 然后再将两种设备放置在同一DP Rank中，根据算力之比进行各个并行维度的分配，同时通过显存公式剪枝；
     * 对符合显存模型约束的备选策略进行profiling，选出最优的一种。
   * 在进行All Reduce时，需要给梯度进行加权平均，权重即为算力比。


### 下周工作

准备答辩

### 导师点评

本周提出了一种将原本的搜索模式与显存模型应用到异构资源上的想法，但是该想法还有待验证与细化。
